{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57c4b1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:43.740711Z",
     "start_time": "2023-11-13T02:15:40.901871800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text,padding='max_length', \n",
    "                       max_length = 10, \n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\")\n",
    "# ------- bert_inpu t ------\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a840189b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:43.970893700Z",
     "start_time": "2023-11-13T02:15:43.741710500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }\n",
    "value_to_labels = {\n",
    "    0:'business',\n",
    "    1:'entertainment',\n",
    "    2:'sport',\n",
    "    3:'tech',\n",
    "    4:'politics'\n",
    "}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e757e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:44.349249200Z",
     "start_time": "2023-11-13T02:15:43.972894100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           category                                               text\n0              tech  tv future in the hands of viewers with home th...\n1          business  worldcom boss  left books alone  former worldc...\n2             sport  tigers wary of farrell  gamble  leicester say ...\n3             sport  yeading face newcastle in fa cup premiership s...\n4     entertainment  ocean s twelve raids box office ocean s twelve...\n...             ...                                                ...\n2220       business  cars pull down us retail figures us retail sal...\n2221       politics  kilroy unveils immigration policy ex-chatshow ...\n2222  entertainment  rem announce new glasgow concert us band rem h...\n2223       politics  how political squabbles snowball it s become c...\n2224          sport  souness delight at euro progress boss graeme s...\n\n[2225 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tech</td>\n      <td>tv future in the hands of viewers with home th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>business</td>\n      <td>worldcom boss  left books alone  former worldc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sport</td>\n      <td>tigers wary of farrell  gamble  leicester say ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sport</td>\n      <td>yeading face newcastle in fa cup premiership s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entertainment</td>\n      <td>ocean s twelve raids box office ocean s twelve...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>business</td>\n      <td>cars pull down us retail figures us retail sal...</td>\n    </tr>\n    <tr>\n      <th>2221</th>\n      <td>politics</td>\n      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>entertainment</td>\n      <td>rem announce new glasgow concert us band rem h...</td>\n    </tr>\n    <tr>\n      <th>2223</th>\n      <td>politics</td>\n      <td>how political squabbles snowball it s become c...</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>sport</td>\n      <td>souness delight at euro progress boss graeme s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2225 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  category                                               text\n0     tech  apple release a new iPad and brand new design ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tech</td>\n      <td>apple release a new iPad and brand new design ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\anaconda3\\envs\\google_review\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bbc_text_df = pd.read_csv('bbc-text.csv')\n",
    "predict_df = pd.read_csv('comment_input.csv')\n",
    "\n",
    "# bbc_text_df.head()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(bbc_text_df)\n",
    "df_predict = pd.DataFrame(predict_df)\n",
    "\n",
    "display(df)\n",
    "display(df_predict)\n",
    "\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))\n",
    "\n",
    "#1780 222 223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9876f207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:44.461301500Z",
     "start_time": "2023-11-13T02:15:44.348249300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66e3fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:44.465303100Z",
     "start_time": "2023-11-13T02:15:44.398130400Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "  # 通过Dataset类获取训练和验证集\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    # DataLoader根据batch_size获取数据，训练时选择打乱样本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "  # 判断是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "            \n",
    "    # 开始进入训练循环\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定义两个变量，用于存储训练集的准确率和损失\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "      # 进度条函数tqdm\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(torch.long)\n",
    "            train_label = train_label.to(device)\n",
    "            \n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通过模型得到输出\n",
    "            output = model(input_id, mask)\n",
    "                # 计算损失\n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "                # 计算精度\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "        # 模型更新\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            # ------ 验证模型 -----------\n",
    "            # 定义两个变量，用于存储验证集的准确率和损失\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "      # 不需要计算梯度\n",
    "        with torch.no_grad():\n",
    "                # 循环获取数据集，并用训练好的模型进行验证\n",
    "            for val_input, val_label in val_dataloader:\n",
    "          # 如果有GPU，则使用GPU，接下来的操作同训练\n",
    "                val_label = val_label.to(torch.long)\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "  \n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "            \n",
    "        print(\n",
    "            f'''Epochs: {epoch_num + 1} \n",
    "            | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \n",
    "            | Val Loss: {total_loss_val / len(val_data): .3f} \n",
    "            | Val Accuracy: {total_acc_val / len(val_data): .3f}''') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0d6cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:24:41.664069500Z",
     "start_time": "2023-11-13T02:15:44.401035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:40<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "            | Train Loss:  0.756 \n",
      "            | Train Accuracy:  0.363 \n",
      "            | Val Loss:  0.621 \n",
      "            | Val Accuracy:  0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:42<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "            | Train Loss:  0.454 \n",
      "            | Train Accuracy:  0.753 \n",
      "            | Val Loss:  0.310 \n",
      "            | Val Accuracy:  0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:42<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "            | Train Loss:  0.236 \n",
      "            | Train Accuracy:  0.921 \n",
      "            | Val Loss:  0.148 \n",
      "            | Val Accuracy:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:42<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "            | Train Loss:  0.134 \n",
      "            | Train Accuracy:  0.970 \n",
      "            | Val Loss:  0.087 \n",
      "            | Val Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:42<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "            | Train Loss:  0.083 \n",
      "            | Train Accuracy:  0.987 \n",
      "            | Val Loss:  0.064 \n",
      "            | Val Accuracy:  0.986\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "torch.cuda.empty_cache()\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403ce130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T02:24:46.091789800Z",
     "start_time": "2023-11-13T02:24:41.662069100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.996\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              output = model(input_id, mask)\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc   \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted outputLabel: tech \n",
      "Test Accuracy:  1.000\n"
     ]
    }
   ],
   "source": [
    "def predict_input(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    outputLabel = \"\"\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              output = model(input_id, mask)\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              outputLabel += str(value_to_labels[output.argmax(dim=1).item()]) + \" \"\n",
    "              total_acc_test += acc   \n",
    "    \n",
    "    print(\"Predicted outputLabel:\", outputLabel)\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "predict_input(model, df_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T02:24:46.139489800Z",
     "start_time": "2023-11-13T02:24:46.089789800Z"
    }
   },
   "id": "7ce05b8848f525ee"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T02:24:46.140489700Z",
     "start_time": "2023-11-13T02:24:46.116222500Z"
    }
   },
   "id": "e9d06c9b7b56bc8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
