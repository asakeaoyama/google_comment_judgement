{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingLog202311271526.txt\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "import datetime\n",
    "\n",
    "time = datetime.datetime.today()\n",
    "daytime = time.strftime(\"%Y%m%d%H%M\")\n",
    "logPath = \"logs/\" + \"trainingLog\" + daytime + \".txt\"\n",
    "\n",
    "log = open(logPath, \"a+\")\n",
    "\n",
    "log.write(\"Start logging...\" + daytime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T15:26:51.353682Z",
     "end_time": "2023-11-27T15:26:51.353901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used GPU 1,2\n"
     ]
    }
   ],
   "source": [
    "# Using CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "print(\"Used GPU\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "log.write(\"Used GPU\", os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 7623, 2453, 8111, 7953, 7274, 1993, 3760, 1558,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Test BERT\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "example_text = '餐廳11點開始沒問題，位置保留十分鐘也沒問題'\n",
    "bert_input = tokenizer(example_text,padding='max_length',\n",
    "                       max_length = 10,\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\")\n",
    "# ------- bert_input -----\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:43.842567Z",
     "end_time": "2023-11-27T13:53:45.778874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a840189b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:45.780714Z",
     "end_time": "2023-11-27T13:53:46.044699Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "labels = {'0':0,\n",
    "          '1':1\n",
    "          }\n",
    "value_to_labels = {\n",
    "    0:'bad',\n",
    "    1:'good',\n",
    "}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [label for label in df['rate']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['comment']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e757e0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.049201Z",
     "end_time": "2023-11-27T13:53:46.844795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      rate                                            comment\n0        0  前幾日去家樂福，要出去停車場時，動線設計相當不流暢，開車出入危險，照明也昏暗，尤其接近中午時...\n1        1  接手台糖量販店之後，無論是在商品齊備程度、提供的服務與設施、配合進駐廠商的完全性都遠勝從前台...\n2        1  1.這間家樂福離家裡很近，隨時要補貨都超方便的  2.之前假日都會有一個大型機器人🤖️出現表...\n3        0  使用外送平台點了一包鴻禧菇，結果送來這種快要壞掉發臭的菇，根本就不能吃，東西壞了能不能就別拿...\n4        1  是我目前逛過全高雄市最好的家樂福、開車🚗好停車還不用收費、顧客水準品質普遍比較高、大多為小家...\n...    ...                                                ...\n5141     0                                              外觀有感。\n5142     1                                               風景很好\n5143     1                                               風景優美\n5144     1                                              很棒的體驗\n5145     1                                            環境不錯👍 …\n\n[5146 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rate</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>前幾日去家樂福，要出去停車場時，動線設計相當不流暢，開車出入危險，照明也昏暗，尤其接近中午時...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>接手台糖量販店之後，無論是在商品齊備程度、提供的服務與設施、配合進駐廠商的完全性都遠勝從前台...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.這間家樂福離家裡很近，隨時要補貨都超方便的  2.之前假日都會有一個大型機器人🤖️出現表...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>使用外送平台點了一包鴻禧菇，結果送來這種快要壞掉發臭的菇，根本就不能吃，東西壞了能不能就別拿...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>是我目前逛過全高雄市最好的家樂福、開車🚗好停車還不用收費、顧客水準品質普遍比較高、大多為小家...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5141</th>\n      <td>0</td>\n      <td>外觀有感。</td>\n    </tr>\n    <tr>\n      <th>5142</th>\n      <td>1</td>\n      <td>風景很好</td>\n    </tr>\n    <tr>\n      <th>5143</th>\n      <td>1</td>\n      <td>風景優美</td>\n    </tr>\n    <tr>\n      <th>5144</th>\n      <td>1</td>\n      <td>很棒的體驗</td>\n    </tr>\n    <tr>\n      <th>5145</th>\n      <td>1</td>\n      <td>環境不錯👍 …</td>\n    </tr>\n  </tbody>\n</table>\n<p>5146 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4116 515 515\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log.write(\"Importing csv data...\")\n",
    "comment_text_df = pd.read_csv('../database/commentData.csv')\n",
    "\n",
    "# bbc_text_df.head()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(comment_text_df)\n",
    "\n",
    "display(df)\n",
    "log.write(\"splitting the dataset...\")\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))\n",
    "log.write(\"len of the dataframes (train, val, test): \", len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9876f207",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.846397Z",
     "end_time": "2023-11-27T13:53:46.914801Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66e3fbc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.889127Z",
     "end_time": "2023-11-27T13:53:46.914930Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    log.write(\"Training...\")\n",
    "  # 通过Dataset类获取训练和验证集\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    # DataLoader根据batch_size获取数据，训练时选择打乱样本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "  # 判断是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            log.write(\"Using CUDA!\")\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 开始进入训练循环\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定义两个变量，用于存储训练集的准确率和损失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 进度条函数tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通过模型得到输出\n",
    "                output = model(input_id, mask)\n",
    "                # 计算损失\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 计算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            # ------ 验证模型 -----------\n",
    "            # 定义两个变量，用于存储验证集的准确率和损失\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "      # 不需要计算梯度\n",
    "            with torch.no_grad():\n",
    "                # 循环获取数据集，并用训练好的模型进行验证\n",
    "                for val_input, val_label in val_dataloader:\n",
    "          # 如果有GPU，则使用GPU，接下来的操作同训练\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "  \n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f} \n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f} \n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')\n",
    "            log.write(\n",
    "                f'''Epochs: {epoch_num + 1}\n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f}\n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}\n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f}\n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0d6cdb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T09:28:00.230157Z",
     "end_time": "2023-11-07T12:04:16.114386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2058 [00:12<1:22:50,  2.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mDataParallel(model)\n\u001B[1;32m      4\u001B[0m LR \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-6\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 41\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_data, val_data, learning_rate, epochs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# 模型更新\u001B[39;00m\n\u001B[1;32m     40\u001B[0m         model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 41\u001B[0m         \u001B[43mbatch_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# ------ 验证模型 -----------\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# 定义两个变量，用于存储验证集的准确率和损失\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/google-comment/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/google-comment/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "model = nn.DataParallel(model)\n",
    "LR = 1e-6\n",
    "log.write(\"Epoch:\", EPOCHS)\n",
    "log.write((\"LR:\", LR))\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ce130",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T12:04:16.753699Z",
     "end_time": "2023-11-07T12:05:32.780633Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              output = model(input_id, mask)\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc   \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/state_model_20231127.pt\n"
     ]
    }
   ],
   "source": [
    "day = time.strftime('%Y%m%d')\n",
    "modelPath = \"models/state_model_\" + day + \".pt\"\n",
    "log.write(\"Saving the trained model...\")\n",
    "torch.save(model.state_dict(), modelPath)\n",
    "log.write(\"Model has saved in models folder, name is \" + modelPath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T15:15:02.303651Z",
     "end_time": "2023-11-27T15:15:02.305135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log.write(\"Cleaning cache in GPU memory...\")\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log.write(\"Done!\")\n",
    "log.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
