{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingLog202311271526.txt\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "import datetime\n",
    "\n",
    "time = datetime.datetime.today()\n",
    "daytime = time.strftime(\"%Y%m%d%H%M\")\n",
    "logPath = \"logs/\" + \"trainingLog\" + daytime + \".txt\"\n",
    "\n",
    "log = open(logPath, \"a+\")\n",
    "\n",
    "log.write(\"Start logging...\" + daytime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T15:26:51.353682Z",
     "end_time": "2023-11-27T15:26:51.353901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used GPU 1,2\n"
     ]
    }
   ],
   "source": [
    "# Using CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "print(\"Used GPU\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "log.write(\"Used GPU\", os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 7623, 2453, 8111, 7953, 7274, 1993, 3760, 1558,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Test BERT\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "example_text = 'é¤å»³11é»é–‹å§‹æ²’å•é¡Œï¼Œä½ç½®ä¿ç•™ååˆ†é˜ä¹Ÿæ²’å•é¡Œ'\n",
    "bert_input = tokenizer(example_text,padding='max_length',\n",
    "                       max_length = 10,\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\")\n",
    "# ------- bert_input -----\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:43.842567Z",
     "end_time": "2023-11-27T13:53:45.778874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a840189b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:45.780714Z",
     "end_time": "2023-11-27T13:53:46.044699Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "labels = {'0':0,\n",
    "          '1':1\n",
    "          }\n",
    "value_to_labels = {\n",
    "    0:'bad',\n",
    "    1:'good',\n",
    "}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [label for label in df['rate']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['comment']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e757e0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.049201Z",
     "end_time": "2023-11-27T13:53:46.844795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      rate                                            comment\n0        0  å‰å¹¾æ—¥å»å®¶æ¨‚ç¦ï¼Œè¦å‡ºå»åœè»Šå ´æ™‚ï¼Œå‹•ç·šè¨­è¨ˆç›¸ç•¶ä¸æµæš¢ï¼Œé–‹è»Šå‡ºå…¥å±éšªï¼Œç…§æ˜ä¹Ÿæ˜æš—ï¼Œå°¤å…¶æ¥è¿‘ä¸­åˆæ™‚...\n1        1  æ¥æ‰‹å°ç³–é‡è²©åº—ä¹‹å¾Œï¼Œç„¡è«–æ˜¯åœ¨å•†å“é½Šå‚™ç¨‹åº¦ã€æä¾›çš„æœå‹™èˆ‡è¨­æ–½ã€é…åˆé€²é§å» å•†çš„å®Œå…¨æ€§éƒ½é å‹å¾å‰å°...\n2        1  1.é€™é–“å®¶æ¨‚ç¦é›¢å®¶è£¡å¾ˆè¿‘ï¼Œéš¨æ™‚è¦è£œè²¨éƒ½è¶…æ–¹ä¾¿çš„  2.ä¹‹å‰å‡æ—¥éƒ½æœƒæœ‰ä¸€å€‹å¤§å‹æ©Ÿå™¨äººğŸ¤–ï¸å‡ºç¾è¡¨...\n3        0  ä½¿ç”¨å¤–é€å¹³å°é»äº†ä¸€åŒ…é´»ç¦§è‡ï¼Œçµæœé€ä¾†é€™ç¨®å¿«è¦å£æ‰ç™¼è‡­çš„è‡ï¼Œæ ¹æœ¬å°±ä¸èƒ½åƒï¼Œæ±è¥¿å£äº†èƒ½ä¸èƒ½å°±åˆ¥æ‹¿...\n4        1  æ˜¯æˆ‘ç›®å‰é€›éå…¨é«˜é›„å¸‚æœ€å¥½çš„å®¶æ¨‚ç¦ã€é–‹è»ŠğŸš—å¥½åœè»Šé‚„ä¸ç”¨æ”¶è²»ã€é¡§å®¢æ°´æº–å“è³ªæ™®éæ¯”è¼ƒé«˜ã€å¤§å¤šç‚ºå°å®¶...\n...    ...                                                ...\n5141     0                                              å¤–è§€æœ‰æ„Ÿã€‚\n5142     1                                               é¢¨æ™¯å¾ˆå¥½\n5143     1                                               é¢¨æ™¯å„ªç¾\n5144     1                                              å¾ˆæ£’çš„é«”é©—\n5145     1                                            ç’°å¢ƒä¸éŒ¯ğŸ‘ â€¦\n\n[5146 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rate</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>å‰å¹¾æ—¥å»å®¶æ¨‚ç¦ï¼Œè¦å‡ºå»åœè»Šå ´æ™‚ï¼Œå‹•ç·šè¨­è¨ˆç›¸ç•¶ä¸æµæš¢ï¼Œé–‹è»Šå‡ºå…¥å±éšªï¼Œç…§æ˜ä¹Ÿæ˜æš—ï¼Œå°¤å…¶æ¥è¿‘ä¸­åˆæ™‚...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>æ¥æ‰‹å°ç³–é‡è²©åº—ä¹‹å¾Œï¼Œç„¡è«–æ˜¯åœ¨å•†å“é½Šå‚™ç¨‹åº¦ã€æä¾›çš„æœå‹™èˆ‡è¨­æ–½ã€é…åˆé€²é§å» å•†çš„å®Œå…¨æ€§éƒ½é å‹å¾å‰å°...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.é€™é–“å®¶æ¨‚ç¦é›¢å®¶è£¡å¾ˆè¿‘ï¼Œéš¨æ™‚è¦è£œè²¨éƒ½è¶…æ–¹ä¾¿çš„  2.ä¹‹å‰å‡æ—¥éƒ½æœƒæœ‰ä¸€å€‹å¤§å‹æ©Ÿå™¨äººğŸ¤–ï¸å‡ºç¾è¡¨...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>ä½¿ç”¨å¤–é€å¹³å°é»äº†ä¸€åŒ…é´»ç¦§è‡ï¼Œçµæœé€ä¾†é€™ç¨®å¿«è¦å£æ‰ç™¼è‡­çš„è‡ï¼Œæ ¹æœ¬å°±ä¸èƒ½åƒï¼Œæ±è¥¿å£äº†èƒ½ä¸èƒ½å°±åˆ¥æ‹¿...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>æ˜¯æˆ‘ç›®å‰é€›éå…¨é«˜é›„å¸‚æœ€å¥½çš„å®¶æ¨‚ç¦ã€é–‹è»ŠğŸš—å¥½åœè»Šé‚„ä¸ç”¨æ”¶è²»ã€é¡§å®¢æ°´æº–å“è³ªæ™®éæ¯”è¼ƒé«˜ã€å¤§å¤šç‚ºå°å®¶...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5141</th>\n      <td>0</td>\n      <td>å¤–è§€æœ‰æ„Ÿã€‚</td>\n    </tr>\n    <tr>\n      <th>5142</th>\n      <td>1</td>\n      <td>é¢¨æ™¯å¾ˆå¥½</td>\n    </tr>\n    <tr>\n      <th>5143</th>\n      <td>1</td>\n      <td>é¢¨æ™¯å„ªç¾</td>\n    </tr>\n    <tr>\n      <th>5144</th>\n      <td>1</td>\n      <td>å¾ˆæ£’çš„é«”é©—</td>\n    </tr>\n    <tr>\n      <th>5145</th>\n      <td>1</td>\n      <td>ç’°å¢ƒä¸éŒ¯ğŸ‘ â€¦</td>\n    </tr>\n  </tbody>\n</table>\n<p>5146 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4116 515 515\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log.write(\"Importing csv data...\")\n",
    "comment_text_df = pd.read_csv('../database/commentData.csv')\n",
    "\n",
    "# bbc_text_df.head()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(comment_text_df)\n",
    "\n",
    "display(df)\n",
    "log.write(\"splitting the dataset...\")\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))\n",
    "log.write(\"len of the dataframes (train, val, test): \", len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9876f207",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.846397Z",
     "end_time": "2023-11-27T13:53:46.914801Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66e3fbc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T13:53:46.889127Z",
     "end_time": "2023-11-27T13:53:46.914930Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    log.write(\"Training...\")\n",
    "  # é€šè¿‡Datasetç±»è·å–è®­ç»ƒå’ŒéªŒè¯é›†\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    # DataLoaderæ ¹æ®batch_sizeè·å–æ•°æ®ï¼Œè®­ç»ƒæ—¶é€‰æ‹©æ‰“ä¹±æ ·æœ¬\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            log.write(\"Using CUDA!\")\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # å¼€å§‹è¿›å…¥è®­ç»ƒå¾ªç¯\n",
    "    for epoch_num in range(epochs):\n",
    "      # å®šä¹‰ä¸¤ä¸ªå˜é‡ï¼Œç”¨äºå­˜å‚¨è®­ç»ƒé›†çš„å‡†ç¡®ç‡å’ŒæŸå¤±\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # è¿›åº¦æ¡å‡½æ•°tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # é€šè¿‡æ¨¡å‹å¾—åˆ°è¾“å‡º\n",
    "                output = model(input_id, mask)\n",
    "                # è®¡ç®—æŸå¤±\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # è®¡ç®—ç²¾åº¦\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # æ¨¡å‹æ›´æ–°\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            # ------ éªŒè¯æ¨¡å‹ -----------\n",
    "            # å®šä¹‰ä¸¤ä¸ªå˜é‡ï¼Œç”¨äºå­˜å‚¨éªŒè¯é›†çš„å‡†ç¡®ç‡å’ŒæŸå¤±\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "      # ä¸éœ€è¦è®¡ç®—æ¢¯åº¦\n",
    "            with torch.no_grad():\n",
    "                # å¾ªç¯è·å–æ•°æ®é›†ï¼Œå¹¶ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡ŒéªŒè¯\n",
    "                for val_input, val_label in val_dataloader:\n",
    "          # å¦‚æœæœ‰GPUï¼Œåˆ™ä½¿ç”¨GPUï¼Œæ¥ä¸‹æ¥çš„æ“ä½œåŒè®­ç»ƒ\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "  \n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f} \n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f} \n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')\n",
    "            log.write(\n",
    "                f'''Epochs: {epoch_num + 1}\n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f}\n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}\n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f}\n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0d6cdb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T09:28:00.230157Z",
     "end_time": "2023-11-07T12:04:16.114386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2058 [00:12<1:22:50,  2.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mDataParallel(model)\n\u001B[1;32m      4\u001B[0m LR \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-6\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 41\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_data, val_data, learning_rate, epochs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# æ¨¡å‹æ›´æ–°\u001B[39;00m\n\u001B[1;32m     40\u001B[0m         model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 41\u001B[0m         \u001B[43mbatch_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# ------ éªŒè¯æ¨¡å‹ -----------\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;66;03m# å®šä¹‰ä¸¤ä¸ªå˜é‡ï¼Œç”¨äºå­˜å‚¨éªŒè¯é›†çš„å‡†ç¡®ç‡å’ŒæŸå¤±\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/google-comment/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/google-comment/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "model = nn.DataParallel(model)\n",
    "LR = 1e-6\n",
    "log.write(\"Epoch:\", EPOCHS)\n",
    "log.write((\"LR:\", LR))\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ce130",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T12:04:16.753699Z",
     "end_time": "2023-11-07T12:05:32.780633Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              output = model(input_id, mask)\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc   \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/state_model_20231127.pt\n"
     ]
    }
   ],
   "source": [
    "day = time.strftime('%Y%m%d')\n",
    "modelPath = \"models/state_model_\" + day + \".pt\"\n",
    "log.write(\"Saving the trained model...\")\n",
    "torch.save(model.state_dict(), modelPath)\n",
    "log.write(\"Model has saved in models folder, name is \" + modelPath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T15:15:02.303651Z",
     "end_time": "2023-11-27T15:15:02.305135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log.write(\"Cleaning cache in GPU memory...\")\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log.write(\"Done!\")\n",
    "log.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
